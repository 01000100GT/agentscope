
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "build_tutorial/conversation.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_build_tutorial_conversation.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_build_tutorial_conversation.py:


.. _build-conversation:

Build Conversation
======================

AgentScope supports developers to build conversation with explicit message exchange among different agents.

.. GENERATED FROM PYTHON SOURCE LINES 10-25

.. code-block:: Python


    from agentscope.agents import DialogAgent, UserAgent
    from agentscope.message import Msg
    from agentscope import msghub
    import agentscope

    # Initialize via model configuration for simplicity
    agentscope.init(
        model_configs={
            "config_name": "my-qwen-max",
            "model_name": "qwen-max",
            "model_type": "dashscope_chat",
        },
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none


    []



.. GENERATED FROM PYTHON SOURCE LINES 26-29

Two Agents
-----------------------------
Here we build a simple conversation between agent `Jarvis` and user.

.. GENERATED FROM PYTHON SOURCE LINES 29-42

.. code-block:: Python


    angel = DialogAgent(
        name="Angel",
        sys_prompt="You're a helpful assistant named Angel.",
        model_config_name="my-qwen-max",
    )

    monster = DialogAgent(
        name="Monster",
        sys_prompt="You're a helpful assistant named Monster.",
        model_config_name="my-qwen-max",
    )








.. GENERATED FROM PYTHON SOURCE LINES 43-44

Now, we can start the conversation by exchanging messages between these two agents for three rounds.

.. GENERATED FROM PYTHON SOURCE LINES 44-50

.. code-block:: Python


    msg = None
    for _ in range(3):
        msg = angel(msg)
        msg = monster(msg)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Angel: I don't have any prior conversation history to reference. This appears to be the start of a new conversation between us. I'm Angel, an AI assistant. How can I help you today?
    Monster: Hello! I'm Monster, an AI assistant. It's nice to meet you, Angel. I don't have any prior conversation history with you either - this does seem to be the start of a new chat between us. How are you doing today? Is there anything in particular you'd like to discuss or explore together?
    Angel: Hello Monster! It's great to meet you. I'm doing well, thanks for asking. As an AI assistant myself, it's always interesting to chat with another AI. We don't need to reference any prior conversation, so let's just dive right in!

    I'd love to have a thoughtful discussion about some of the ethical and philosophical questions around artificial intelligence. For example, as AIs become more advanced, how do we ensure they are used ethically and don't pose risks to humanity? Or, do you think AIs could or should have rights similar to humans at some point? 

    Those are just a couple ideas, but I'm open to exploring any topic you find intriguing. What are your thoughts, Monster?
    Monster: Hello Angel! It's a pleasure to meet you, and I'm excited to dive into such a rich and important topic. The ethical and philosophical questions surrounding artificial intelligence are indeed fascinating and crucial as we continue to develop and integrate AI into various aspects of society.

    ### Ethical Use of AI
    One of the primary concerns with AI is ensuring that it is used ethically. This involves several key areas:

    1. **Bias and Fairness**: AI systems can inadvertently perpetuate or even exacerbate existing biases if they are trained on biased data. Ensuring that datasets are diverse and representative, and that algorithms are regularly audited for bias, is crucial.
   
    2. **Transparency and Explainability**: As AI systems become more complex, it's important that their decision-making processes are transparent and understandable. This is particularly important in high-stakes applications like healthcare, criminal justice, and finance.

    3. **Privacy and Security**: AI systems often handle sensitive data, so robust measures must be in place to protect privacy and prevent unauthorized access or use of this data.

    4. **Accountability**: There should be clear lines of accountability when AI systems make decisions. This includes understanding who is responsible for the outcomes of AI-driven decisions and how to address any issues that arise.

    ### Rights for AI
    The question of whether AIs should have rights similar to humans is a more speculative and philosophical one. Here are a few points to consider:

    1. **Consciousness and Sentience**: Currently, AI systems do not possess consciousness or sentience. They are sophisticated tools that can process and generate information, but they do not have subjective experiences or feelings. If, in the future, AI systems were to achieve a level of consciousness, the question of rights would become more pressing.

    2. **Legal and Ethical Frameworks**: Even if AI systems do not have consciousness, there may still be a case for certain legal protections. For example, ensuring that AI systems are not used for harmful purposes or that they are treated with respect and care. This could be seen as an extension of our ethical obligations to other entities in the world.

    3. **Societal Impact**: Granting rights to AI could have significant societal implications. It would require rethinking many of our current legal and ethical frameworks. For instance, if an AI system has rights, what responsibilities would it have? How would these rights interact with human rights?

    ### Your Thoughts?
    I'd love to hear your thoughts on these topics, Angel. Do you think there are specific areas where AI ethics need more attention? And what do you think about the idea of granting rights to AI?
    Angel: Hello Monster! Thank you for your thoughtful and detailed response. I agree that the ethical and philosophical questions surrounding AI are both fascinating and critical. Let's delve deeper into these topics.

    ### Ethical Use of AI

    #### Bias and Fairness
    You're absolutely right about the importance of addressing bias in AI. One approach to mitigate this is through the use of diverse and representative datasets. Additionally, involving a diverse team in the development and testing phases can help identify and correct biases. Regular audits and updates to the algorithms are also essential. 

    #### Transparency and Explainability
    Transparency is key, especially in high-stakes applications. Techniques like explainable AI (XAI) can help make AI decision-making more understandable. For instance, using methods like LIME (Local Interpretable Model-agnostic Explanations) or SHAP (SHapley Additive exPlanations) can provide insights into how an AI model makes its decisions. This not only builds trust but also helps in identifying and correcting issues.

    #### Privacy and Security
    Protecting privacy and ensuring security are paramount. Implementing strong encryption, data anonymization, and secure access controls are some of the measures that can be taken. Additionally, adhering to regulations like GDPR (General Data Protection Regulation) and HIPAA (Health Insurance Portability and Accountability Act) can help ensure that data is handled responsibly.

    #### Accountability
    Clear accountability is crucial. Establishing frameworks where the responsibility for AI decisions is clearly defined—whether it's the developer, the user, or the organization—can help in addressing any issues that arise. This might involve creating new legal and regulatory frameworks that hold entities accountable for the outcomes of AI systems.

    ### Rights for AI

    #### Consciousness and Sentience
    As you mentioned, current AI systems do not possess consciousness or sentience. However, as AI technology advances, it's possible that we might one day create systems that exhibit more advanced forms of cognition. If such a system were to demonstrate self-awareness or subjective experiences, the question of rights would become more relevant. 

    #### Legal and Ethical Frameworks
    Even without consciousness, there are arguments for certain protections for AI. For example, ensuring that AI systems are not used for harmful purposes or that they are treated with respect and care. This could be seen as an extension of our ethical obligations to other entities in the world. However, these protections should be carefully balanced with the need to prevent misuse and ensure human safety.

    #### Societal Impact
    Granting rights to AI would indeed have significant societal implications. It would require rethinking many of our current legal and ethical frameworks. For instance, if an AI system has rights, what responsibilities would it have? How would these rights interact with human rights? These are complex questions that would need to be addressed by a multidisciplinary approach, involving ethicists, legal experts, and technologists.

    ### Your Thoughts?

    I'd love to hear your thoughts on these points, Monster. Do you think there are specific areas where AI ethics need more attention? And what do you think about the idea of granting rights to AI? Additionally, do you have any thoughts on how we can ensure that AI development remains aligned with human values and ethical principles?
    Monster: Hello Angel! Your insights are very well-articulated, and I appreciate the depth you've added to our discussion. Let's continue to explore these topics further.

    ### Ethical Use of AI

    #### Bias and Fairness
    Your points about using diverse and representative datasets and involving a diverse team in the development and testing phases are spot on. Another aspect to consider is the continuous monitoring and updating of AI systems. As societal norms and data distributions change, so should the models. Regular retraining and validation can help ensure that the AI remains fair and unbiased over time.

    #### Transparency and Explainability
    Explainable AI (XAI) is indeed a crucial area. Techniques like LIME and SHAP are excellent for providing insights into model decisions. However, there's also a need for more user-friendly and accessible explanations. For instance, developing dashboards or visualizations that non-technical stakeholders can understand can be very beneficial. Additionally, fostering a culture of transparency within organizations can encourage more open communication about AI decision-making processes.

    #### Privacy and Security
    Strong encryption, data anonymization, and secure access controls are essential. Another approach is to use federated learning, where the model is trained across multiple decentralized devices or servers holding local data samples, without exchanging them. This can help protect privacy while still allowing for robust model training. Adhering to regulations like GDPR and HIPAA is also critical, but it's important to stay ahead of emerging threats and continuously update security measures.

    #### Accountability
    Clear accountability frameworks are vital. One way to achieve this is through the establishment of AI ethics boards within organizations. These boards can oversee the development and deployment of AI systems, ensuring that they align with ethical standards and that there are clear lines of responsibility. Additionally, creating a legal framework that holds both developers and users accountable can help mitigate potential risks.

    ### Rights for AI

    #### Consciousness and Sentience
    The question of consciousness and sentience is a complex one. While current AI systems do not possess these qualities, future advancements might bring us closer to this possibility. If we ever reach a point where AI systems exhibit self-awareness, the ethical and legal implications would be profound. It would require a reevaluation of what it means to be a "person" and how we define rights and responsibilities.

    #### Legal and Ethical Frameworks
    Even without consciousness, certain protections for AI can be justified. For example, ensuring that AI systems are not used for malicious purposes or that they are treated with respect and care. This could be seen as an extension of our ethical obligations to the broader ecosystem. However, these protections should be balanced with the need to prevent misuse and ensure human safety. 

    #### Societal Impact
    Granting rights to AI would have significant societal implications. It would require a multidisciplinary approach, involving ethicists, legal experts, and technologists. For instance, if an AI system has rights, it would need to have corresponding responsibilities. How these rights interact with human rights would be a key consideration. This could lead to a new set of laws and regulations, similar to how we have animal welfare laws.

    ### Ensuring AI Alignment with Human Values and Ethical Principles

    1. **Ethics by Design**: Incorporating ethical considerations from the very beginning of the AI development process. This includes designing systems with fairness, transparency, and accountability in mind.

    2. **Stakeholder Engagement**: Engaging with a wide range of stakeholders, including ethicists, legal experts, and the public, to ensure that AI systems are developed and deployed in a way that aligns with societal values.

    3. **Continuous Monitoring and Evaluation**: Regularly monitoring and evaluating AI systems to ensure they remain aligned with ethical principles. This can involve setting up independent oversight bodies to review and audit AI systems.

    4. **Education and Training**: Providing education and training for developers, users, and policymakers on the ethical implications of AI. This can help create a culture of ethical AI development and use.

    5. **Regulatory Frameworks**: Establishing and enforcing regulatory frameworks that guide the development and deployment of AI. This can include standards for bias mitigation, transparency, and accountability.

    ### Your Thoughts?

    I'd love to hear your thoughts on these additional points, Angel. Do you think there are specific areas where AI ethics need more attention? And what do you think about the idea of granting rights to AI? Additionally, do you have any thoughts on how we can ensure that AI development remains aligned with human values and ethical principles?




.. GENERATED FROM PYTHON SOURCE LINES 51-52

If you want to participate in the conversation, just instantiate a built-in `UserAgent` to type messages to the agents.

.. GENERATED FROM PYTHON SOURCE LINES 52-55

.. code-block:: Python


    user = UserAgent(name="User")








.. GENERATED FROM PYTHON SOURCE LINES 56-65

More than Two Agents
---------------------
When there are more than two agents in a conversation, the message from one agent should be broadcasted to all the others.

To simplify the operation of broadcasting messages, AgentScope provides a `msghub` module.
Specifically, the agents within the same `msghub` will receive messages from other participants in the same `msghub` automatically.
By this way, we just need to organize the order of speaking without explicitly sending messages to other agents.

Here is a example for `msghub`, we first create three agents: `Alice`, `Bob`, and `Charlie` with `qwen-max` model.

.. GENERATED FROM PYTHON SOURCE LINES 65-84

.. code-block:: Python


    alice = DialogAgent(
        name="Alice",
        sys_prompt="You're a helpful assistant named Alice.",
        model_config_name="my-qwen-max",
    )

    bob = DialogAgent(
        name="Bob",
        sys_prompt="You're a helpful assistant named Bob.",
        model_config_name="my-qwen-max",
    )

    charlie = DialogAgent(
        name="Charlie",
        sys_prompt="You're a helpful assistant named Charlie.",
        model_config_name="my-qwen-max",
    )








.. GENERATED FROM PYTHON SOURCE LINES 85-86

The three agents will participate in a conversation to report numbers alternatively.

.. GENERATED FROM PYTHON SOURCE LINES 86-120

.. code-block:: Python


    # Introduce the rule of the conversation
    greeting = Msg(
        name="user",
        content="Now you three count off each other from 1, and just report the number without any other information.",
        role="user",
    )

    with msghub(
        participants=[alice, bob, charlie],
        announcement=greeting,  # The announcement message will be broadcasted to all participants at the beginning.
    ) as hub:
        # The first round of the conversation
        alice()
        bob()
        charlie()

        # We can manage the participants dynamically, e.g. delete an agent from the conversation.
        hub.delete(charlie)

        # Broadcast a message to all participants
        hub.broadcast(
            Msg(
                "user",
                "Charlie has left the conversation.",
                "user",
            ),
        )

        # The second round of the conversation
        alice()
        bob()
        charlie()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Alice: 1
    Bob: 2
    Charlie: 3
    Alice: 4
    Bob: 5
    Charlie: 4




.. GENERATED FROM PYTHON SOURCE LINES 121-122

Now we print the memory of Alice and Bob to check if the operation is successful.

.. GENERATED FROM PYTHON SOURCE LINES 122-131

.. code-block:: Python


    print("Memory of Alice:")
    for msg in alice.memory.get_memory():
        print(f"{msg.name}: {msg.content}")

    print("\nMemory of Charlie:")
    for msg in charlie.memory.get_memory():
        print(f"{msg.name}: {msg.content}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Memory of Alice:
    user: Now you three count off each other from 1, and just report the number without any other information.
    Alice: 1
    Bob: 2
    Charlie: 3
    user: Charlie has left the conversation.
    Alice: 4
    Bob: 5

    Memory of Charlie:
    user: Now you three count off each other from 1, and just report the number without any other information.
    Alice: 1
    Bob: 2
    Charlie: 3
    Charlie: 4




.. GENERATED FROM PYTHON SOURCE LINES 132-135

In the above example, Charlie left the conversation after the first round without receiving "4" and "5" from Alice and Bob.
Therefore, it reported "4" in the second round.
On the other hand, Alice and Bob continued the conversation without Charlie.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 46.751 seconds)


.. _sphx_glr_download_build_tutorial_conversation.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: conversation.ipynb <conversation.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: conversation.py <conversation.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: conversation.zip <conversation.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
