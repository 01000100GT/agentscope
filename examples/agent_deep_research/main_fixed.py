# -*- coding: utf-8 -*-
"""ä¿®å¤ç‰ˆæœ¬çš„æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ç¤ºä¾‹"""

import asyncio
import os
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv

    env_path = Path(__file__).parent.parent.parent / ".env"
    load_dotenv(env_path)
except ImportError:
    print("python-dotenv not installed.")

from agentscope import logger
from agentscope.formatter import OpenAIChatFormatter
from agentscope.memory import InMemoryMemory
from agentscope.model import OpenAIChatModel
from agentscope.message import Msg
from agentscope.mcp import StdIOStatefulClient
from deep_research_agent import DeepResearchAgent


async def main_fixed(user_query: str) -> None:
    """ä¿®å¤ç‰ˆæœ¬çš„ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ä¿®å¤ç‰ˆæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“...")
    print(f"ğŸ“ ç ”ç©¶ä¸»é¢˜: {user_query}")
    print("=" * 60)

    # ç¯å¢ƒå˜é‡æ£€æŸ¥
    tavily_api_key = os.getenv("TAVILY_API_KEY", "")
    if not tavily_api_key:
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½® TAVILY_API_KEYï¼Œæœç´¢åŠŸèƒ½å¯èƒ½å—é™")

    # åˆ›å»ºæœç´¢å®¢æˆ·ç«¯
    try:
        import shutil
        npx_path = shutil.which("npx")
        if not npx_path:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ° npx å‘½ä»¤")
            return
            
        tavily_search_client = StdIOStatefulClient(
            name="tavily_mcp",
            command=npx_path,
            args=["-y", "tavily-mcp@latest"],
            env={"TAVILY_API_KEY": tavily_api_key},
        )
    except Exception as e:
        print(f"âŒ åˆ›å»ºTavilyæœç´¢å®¢æˆ·ç«¯å¤±è´¥: {e}")
        return

    # è·å–è‡ªå®šä¹‰æ¨¡å‹é…ç½®
    api_key = os.environ.get("CUSTOM_OPENAI_API_KEY")
    base_url = os.environ.get("CUSTOM_OPENAI_BASE_URL")
    model_name = os.environ.get(
        "CUSTOM_MODEL_NAME", "gpt-3.5-turbo"
    )

    if not api_key or not base_url:
        raise ValueError("éœ€è¦è®¾ç½® CUSTOM_OPENAI_API_KEY å’Œ CUSTOM_OPENAI_BASE_URL")

    try:
        print("ğŸ¤– åˆå§‹åŒ–ä¿®å¤ç‰ˆç ”ç©¶æ™ºèƒ½ä½“...")
        print(f"   ğŸ¯ æ¨¡å‹: {model_name}")
        print(f"   ğŸŒ API: {base_url}")

        # è¿æ¥åˆ°Tavilyæœç´¢å®¢æˆ·ç«¯
        print("ğŸ”— æ­£åœ¨è¿æ¥åˆ°Tavilyæœç´¢å®¢æˆ·ç«¯...")
        await tavily_search_client.connect()
        print("âœ… Tavilyæœç´¢å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")

        # åˆ›å»ºä¿®å¤çš„æ™ºèƒ½ä½“
        agent = DeepResearchAgent(
            name="Friday",
            sys_prompt="You are Friday, a helpful research assistant.",
            model=OpenAIChatModel(
                model_name=model_name,
                api_key=api_key,
                client_args={"base_url": base_url},
                stream=False,  # å…³é—­æµå¼è¾“å‡ºä»¥æé«˜ç¨³å®šæ€§
                generate_kwargs={
                    "temperature": 0.7,  # é€‚ä¸­çš„æ¸©åº¦
                    "max_tokens": 2048,
                },
            ),
            formatter=OpenAIChatFormatter(),
            memory=InMemoryMemory(),
            search_mcp_client=tavily_search_client,
            max_iters=5,  # å‡å°‘è¿­ä»£æ¬¡æ•°
        )

        # ç­‰å¾…å·¥å…·æ³¨å†Œå®Œæˆ
        print("â³ ç­‰å¾…å·¥å…·æ³¨å†Œå®Œæˆ...")
        await asyncio.sleep(2)  # ç»™å·¥å…·æ³¨å†Œä¸€äº›æ—¶é—´
        print("âœ… å·¥å…·æ³¨å†Œå®Œæˆ")

        print("ğŸ” å¼€å§‹æ·±åº¦ç ”ç©¶...")
        print("â³ è¯·ç¨ç­‰ï¼Œæ­£åœ¨æœç´¢å’Œåˆ†æç›¸å…³ä¿¡æ¯...")
        print("=" * 60)

        # åˆ›å»ºç ”ç©¶è¯·æ±‚
        msg = Msg("user", user_query, "user")

        # æ‰§è¡Œç ”ç©¶
        result = await agent(msg)

        print("\n" + "=" * 60)
        print("ğŸ‰ ç ”ç©¶å®Œæˆ!")
        print("ğŸ“‹ ç ”ç©¶æŠ¥å‘Š:")
        print("=" * 60)
        print(result.get_text_content())
        print("=" * 60)

    except Exception as err:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {err}")
        import traceback
        traceback.print_exc()
    finally:
        try:
            await tavily_search_client.close()
            print("\nğŸ”Œ æ¸…ç†å®Œæˆ")
        except Exception:
            # å¿½ç•¥æ¸…ç†è¿‡ç¨‹ä¸­çš„å¼‚å¸¸ï¼Œä½†ä¸é˜»æ­¢ç¨‹åºé€€å‡º
            pass


if __name__ == "__main__":
    query = (
        "å¦‚æœåŸƒåˆ©ä¹Œå¾·Â·åŸºæ™®ä¹”æ ¼èƒ½å¤Ÿæ— é™æœŸåœ°ä¿æŒä»–åˆ›çºªå½•çš„"
        "é©¬æ‹‰æ¾é…é€Ÿï¼Œé‚£ä¹ˆä»–è·‘å®Œåœ°çƒåˆ°æœˆçƒæœ€è¿‘è·ç¦»"
        "éœ€è¦å¤šå°‘åƒå°æ—¶ï¼Ÿè¯·ä½¿ç”¨ç»´åŸºç™¾ç§‘æœˆçƒé¡µé¢ä¸Šçš„"
        "æœ€å°è¿‘åœ°ç‚¹å€¼æ¥è¿›è¡Œè®¡ç®—ã€‚å°†ç»“æœå››èˆäº”å…¥"
        "åˆ°æœ€æ¥è¿‘çš„1000å°æ—¶ï¼Œå¦‚æœ‰å¿…è¦è¯·ä¸è¦ä½¿ç”¨"
        "ä»»ä½•é€—å·åˆ†éš”ç¬¦ã€‚"
    )
    
    try:
        asyncio.run(main_fixed(query))
    except KeyboardInterrupt:
        print("\nâš ï¸ ç ”ç©¶è¢«ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()