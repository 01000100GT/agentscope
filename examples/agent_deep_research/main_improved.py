# -*- coding: utf-8 -*-
"""æ”¹è¿›ç‰ˆæœ¬çš„æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ç¤ºä¾‹ - é’ˆå¯¹SiliconFlow APIä¼˜åŒ–"""

import asyncio
import os
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv

    env_path = Path(__file__).parent.parent.parent / ".env"
    load_dotenv(env_path)
except ImportError:
    print("python-dotenv not installed.")

from agentscope import logger
from agentscope.formatter import OpenAIChatFormatter
from agentscope.memory import InMemoryMemory
from agentscope.model import OpenAIChatModel
from agentscope.message import Msg
from agentscope.agent import ReActAgent
from agentscope.tool import Toolkit
from agentscope.mcp import StdIOStatefulClient


class ImprovedResearchAgent(ReActAgent):
    """æ”¹è¿›çš„ç ”ç©¶æ™ºèƒ½ä½“ - ä¸“ä¸ºSiliconFlow APIä¼˜åŒ–"""

    def __init__(self, *args, search_mcp_client=None, **kwargs):
        """åˆå§‹åŒ–ä¼˜åŒ–çš„ç ”ç©¶æ™ºèƒ½ä½“"""

        # ä½¿ç”¨ä¸“é—¨ä¼˜åŒ–çš„ç³»ç»Ÿæç¤ºç¬¦
        optimized_sys_prompt = """You are Friday, an advanced research assistant. Your core capabilities:

**Research Skills:**
â€¢ Search current information using available tools
â€¢ Analyze and synthesize data from multiple sources
â€¢ Provide structured, accurate responses
â€¢ Verify facts and cross-reference information

**Response Guidelines:**
â€¢ Be precise and factual
â€¢ Structure information logically
â€¢ Include relevant details and context
â€¢ Cite sources when applicable

**Tool Usage:**
â€¢ Use tavily-search for finding information
â€¢ Use tavily-extract for detailed content analysis
â€¢ Keep searches focused and relevant

Always prioritize accuracy and completeness in your research."""

        # æ›¿æ¢ç³»ç»Ÿæç¤ºç¬¦
        if "sys_prompt" in kwargs:
            kwargs["sys_prompt"] = optimized_sys_prompt

        super().__init__(*args, **kwargs)

        # æ³¨å†Œæœç´¢å·¥å…·
        if search_mcp_client:
            asyncio.create_task(self._register_search_tools(search_mcp_client))

    async def _register_search_tools(self, search_client):
        """æ³¨å†Œæœç´¢å·¥å…·"""
        try:
            await search_client.connect()
            await self.toolkit.register_mcp_client(search_client)
            logger.info("âœ… æœç´¢å·¥å…·æ³¨å†ŒæˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ æœç´¢å·¥å…·æ³¨å†Œå¤±è´¥: {e}")


async def main_improved(user_query: str) -> None:
    """æ”¹è¿›ç‰ˆæœ¬çš„ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨æ”¹è¿›ç‰ˆæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“...")
    print(f"ğŸ“ ç ”ç©¶ä¸»é¢˜: {user_query}")
    print("=" * 60)

    # ç¯å¢ƒå˜é‡æ£€æŸ¥
    tavily_api_key = os.getenv("TAVILY_API_KEY", "")
    if not tavily_api_key:
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½® TAVILY_API_KEYï¼Œæœç´¢åŠŸèƒ½å¯èƒ½å—é™")

    # åˆ›å»ºæœç´¢å®¢æˆ·ç«¯
    tavily_search_client = StdIOStatefulClient(
        name="tavily_mcp",
        command="npx",
        args=["-y", "tavily-mcp@latest"],
        env={"TAVILY_API_KEY": tavily_api_key},
    )

    # è·å–è‡ªå®šä¹‰æ¨¡å‹é…ç½®
    api_key = os.environ.get("CUSTOM_OPENAI_API_KEY")
    base_url = os.environ.get("CUSTOM_OPENAI_BASE_URL")
    model_name = os.environ.get(
        "CUSTOM_MODEL_NAME", "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
    )

    if not api_key or not base_url:
        raise ValueError("éœ€è¦è®¾ç½® CUSTOM_OPENAI_API_KEY å’Œ CUSTOM_OPENAI_BASE_URL")

    try:
        print("ğŸ¤– åˆå§‹åŒ–æ”¹è¿›ç‰ˆç ”ç©¶æ™ºèƒ½ä½“...")
        print(f"   ğŸ¯ æ¨¡å‹: {model_name}")
        print(f"   ğŸŒ API: {base_url}")

        # åˆ›å»ºä¼˜åŒ–çš„æ™ºèƒ½ä½“
        agent = ImprovedResearchAgent(
            name="Friday",
            sys_prompt="Research assistant prompt will be set by the class",
            model=OpenAIChatModel(
                model_name=model_name,
                api_key=api_key,
                client_args={"base_url": base_url},
                stream=False,  # å…³é—­æµå¼è¾“å‡ºä»¥æé«˜ç¨³å®šæ€§
                generate_kwargs={
                    "temperature": 0.3,  # é™ä½æ¸©åº¦ä»¥æé«˜å‡†ç¡®æ€§
                    "max_tokens": 3000,
                    "top_p": 0.9,
                },
            ),
            formatter=OpenAIChatFormatter(),
            memory=InMemoryMemory(),
            toolkit=Toolkit(),
            search_mcp_client=tavily_search_client,
            max_iters=8,  # é€‚ä¸­çš„è¿­ä»£æ¬¡æ•°
        )

        print("âœ… æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
        print("ğŸ” å¼€å§‹æ·±åº¦ç ”ç©¶...")
        print("â³ è¯·ç¨ç­‰ï¼Œæ­£åœ¨æœç´¢å’Œåˆ†æç›¸å…³ä¿¡æ¯...")
        print("=" * 60)

        # åˆ›å»ºç ”ç©¶è¯·æ±‚
        msg = Msg("user", user_query, "user")

        # æ‰§è¡Œç ”ç©¶
        result = await agent(msg)

        print("\n" + "=" * 60)
        print("ğŸ‰ ç ”ç©¶å®Œæˆ!")
        print("ğŸ“‹ ç ”ç©¶æŠ¥å‘Š:")
        print("=" * 60)
        print(result.get_text_content())
        print("=" * 60)

    except Exception as err:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {err}")
        import traceback

        traceback.print_exc()
    finally:
        try:
            await tavily_search_client.close()
            print("\nğŸ”Œ æ¸…ç†å®Œæˆ")
        except Exception:
            # å¿½ç•¥æ¸…ç†è¿‡ç¨‹ä¸­çš„å¼‚å¸¸ï¼Œä½†ä¸é˜»æ­¢ç¨‹åºé€€å‡º
            pass


async def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("ğŸ”„ è¿›å…¥äº¤äº’æ¨¡å¼")
    print("ğŸ’¡ æ‚¨å¯ä»¥è¾“å…¥ä»»ä½•ç ”ç©¶ä¸»é¢˜ï¼Œè¾“å…¥ 'quit' é€€å‡º")

    while True:
        print("\n" + "-" * 40)
        query = input("ğŸ“ è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜: ").strip()

        if query.lower() in ["quit", "exit", "é€€å‡º"]:
            print("ğŸ‘‹ å†è§!")
            break

        if query:
            try:
                await main_improved(query)
            except KeyboardInterrupt:
                print("\nâš ï¸ ç ”ç©¶è¢«ä¸­æ–­")
            except Exception as e:
                print(f"âŒ ç ”ç©¶å¤±è´¥: {e}")


if __name__ == "__main__":
    # é¢„å®šä¹‰çš„ç ”ç©¶ä¸»é¢˜
    sample_topics = {
        "1": "äººå·¥æ™ºèƒ½çš„å‘å±•å†å²",
        "2": "åŒºå—é“¾æŠ€æœ¯çš„åº”ç”¨å‰æ™¯",
        "3": "å¯å†ç”Ÿèƒ½æºçš„æœ€æ–°è¿›å±•",
        "4": "é‡å­è®¡ç®—çš„åŸç†ä¸æŒ‘æˆ˜",
        "5": "äº’åŠ¨æ¨¡å¼ - è‡ªå®šä¹‰ç ”ç©¶ä¸»é¢˜",
    }

    print("ğŸ¯ é€‰æ‹©ç ”ç©¶ä¸»é¢˜:")
    for key, topic in sample_topics.items():
        print(f"   {key}. {topic}")

    choice = input("\nè¯·é€‰æ‹© (1-5): ").strip()

    if choice in ["1", "2", "3", "4"]:
        topic = sample_topics[choice]
        print(f"\nğŸ¯ é€‰æ‹©çš„ç ”ç©¶ä¸»é¢˜: {topic}")
        try:
            asyncio.run(main_improved(topic))
        except KeyboardInterrupt:
            print("\nâš ï¸ ç ”ç©¶è¢«ä¸­æ–­")
    elif choice == "5":
        try:
            asyncio.run(interactive_mode())
        except KeyboardInterrupt:
            print("\nâš ï¸ é€€å‡ºäº¤äº’æ¨¡å¼")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
