# -*- coding: utf-8 -*-
"""The main entry point of the Deep Research agent example."""
# æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ç¤ºä¾‹çš„ä¸»å…¥å£ç‚¹

import asyncio  # å¯¼å…¥å¼‚æ­¥IOåº“
import os  # å¯¼å…¥æ“ä½œç³»ç»Ÿæ¥å£æ¨¡å—
from pathlib import Path  # å¯¼å…¥è·¯å¾„å¤„ç†æ¨¡å—

# Load environment variables from .env file
# ä».envæ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv  # å¯¼å…¥ç¯å¢ƒå˜é‡åŠ è½½å™¨

    # Look for .env file in project root
    # åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸­æŸ¥æ‰¾.envæ–‡ä»¶
    env_path = Path(__file__).parent.parent.parent / ".env"  # æ„å»º.envæ–‡ä»¶è·¯å¾„
    print(f"ğŸ” å°è¯•åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
    result = load_dotenv(env_path)  # åŠ è½½ç¯å¢ƒå˜é‡
    print(f"   åŠ è½½ç»“æœ: {result}")
    
    # éªŒè¯ç¯å¢ƒå˜é‡æ˜¯å¦åŠ è½½æˆåŠŸ
    tavily_key = os.environ.get("TAVILY_API_KEY")
    if tavily_key:
        print(f"âœ… TAVILY_API_KEY å·²æˆåŠŸåŠ è½½ï¼Œé•¿åº¦: {len(tavily_key)} å­—ç¬¦")
    else:
        print("âš ï¸ TAVILY_API_KEY æœªæ‰¾åˆ°")
except ImportError:
    print(
        "python-dotenv not installed. Please install it with: pip install python-dotenv"
    )  # æç¤ºæœªå®‰è£…python-dotenv
    print("Or set environment variables manually.")  # æç¤ºæ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡

from deep_research_agent import DeepResearchAgent  # å¯¼å…¥æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“

from agentscope import logger  # å¯¼å…¥æ—¥å¿—è®°å½•å™¨
from agentscope.formatter import OpenAIChatFormatter  # å¯¼å…¥OpenAIèŠå¤©æ ¼å¼åŒ–å™¨
from agentscope.memory import InMemoryMemory  # å¯¼å…¥å†…å­˜å­˜å‚¨
from agentscope.model import OpenAIChatModel  # å¯¼å…¥OpenAIèŠå¤©æ¨¡å‹
from agentscope.message import Msg  # å¯¼å…¥æ¶ˆæ¯ç±»
from agentscope.mcp import StdIOStatefulClient  # å¯¼å…¥æ ‡å‡†è¾“å…¥è¾“å‡ºæœ‰çŠ¶æ€å®¢æˆ·ç«¯


async def main(user_query: str) -> None:  # å®šä¹‰ä¸»å¼‚æ­¥å‡½æ•°ï¼Œæ¥æ”¶ç”¨æˆ·æŸ¥è¯¢å‚æ•°
    """The main entry point for the Deep Research agent example."""
    # æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“ç¤ºä¾‹çš„ä¸»å…¥å£ç‚¹
    logger.setLevel(level="DEBUG")  # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºDEBUG

    # æ£€æŸ¥ç¯å¢ƒå˜é‡å’Œä¾èµ–
    # é¦–å…ˆæ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦è¢«æ­£ç¡®åŠ è½½
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒå˜é‡åŠ è½½æƒ…å†µ:")
    tavily_api_key: str | None = os.environ.get("TAVILY_API_KEY")
    print(f"   TAVILY_API_KEY: {'å·²è®¾ç½®' if tavily_api_key else 'æœªè®¾ç½®'}")
    if tavily_api_key:
        print(f"   APIå¯†é’¥é•¿åº¦: {len(tavily_api_key)} å­—ç¬¦")
        print(f"   APIå¯†é’¥å‰ç¼€: {tavily_api_key[:10]}...")

    if not tavily_api_key:
        print("âš ï¸ è­¦å‘Š: æœªè®¾ç½® TAVILY_API_KEYï¼Œæœç´¢åŠŸèƒ½å¯èƒ½å—é™")

    # æ£€æŸ¥ npx æ˜¯å¦å¯ç”¨
    import shutil

    npx_path = shutil.which("npx")
    if not npx_path:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° npx å‘½ä»¤")
        print("ğŸ’¡ å»ºè®®: ä½¿ç”¨ main_no_search.py è¿è¡Œä¸éœ€è¦æœç´¢å·¥å…·çš„ç‰ˆæœ¬")
        print("æˆ–è€…ç¡®ä¿ Node.js å·²æ­£ç¡®å®‰è£…å¹¶åœ¨ PATH ä¸­")
        return

    print(f"âœ… æ‰¾åˆ° npx: {npx_path}")

    tavily_search_client: StdIOStatefulClient = (
        StdIOStatefulClient(  # åˆ›å»ºTavilyæœç´¢å®¢æˆ·ç«¯
            name="tavily_mcp",  # è®¾ç½®å®¢æˆ·ç«¯åç§°
            command=npx_path,  # ä½¿ç”¨å®Œæ•´è·¯å¾„
            args=["-y", "tavily-mcp@latest"],  # è®¾ç½®å‘½ä»¤å‚æ•°
            env={"TAVILY_API_KEY": tavily_api_key or ""},  # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ŒåŒ…å«APIå¯†é’¥
        )
    )

    default_working_dir = os.path.join(  # æ„å»ºé»˜è®¤å·¥ä½œç›®å½•è·¯å¾„
        os.path.dirname(__file__),  # è·å–å½“å‰æ–‡ä»¶ç›®å½•
        "deepresearch_agent_demo_env",  # æ·»åŠ å­ç›®å½•å
    )
    agent_working_dir = os.getenv(  # è·å–æ™ºèƒ½ä½“å·¥ä½œç›®å½•
        "AGENT_OPERATION_DIR",  # ç¯å¢ƒå˜é‡å
        default_working_dir,  # é»˜è®¤å€¼
    )
    os.makedirs(agent_working_dir, exist_ok=True)  # åˆ›å»ºå·¥ä½œç›®å½•ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™å¿½ç•¥

    try:
        # Get custom OpenAI API configuration
        # è·å–è‡ªå®šä¹‰OpenAI APIé…ç½®
        api_key = os.environ.get("CUSTOM_OPENAI_API_KEY")  # è·å–APIå¯†é’¥
        base_url = os.environ.get("CUSTOM_OPENAI_BASE_URL")  # è·å–åŸºç¡€URL
        model_name = os.environ.get(
            "CUSTOM_MODEL_NAME", "gpt-3.5-turbo"
        )  # è·å–æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºgpt-3.5-turbo

        if api_key is None:  # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
            raise ValueError(
                "CUSTOM_OPENAI_API_KEY environment variable is required"
            )  # æŠ›å‡ºé”™è¯¯ï¼šéœ€è¦APIå¯†é’¥ç¯å¢ƒå˜é‡
        if base_url is None:  # æ£€æŸ¥åŸºç¡€URLæ˜¯å¦å­˜åœ¨
            raise ValueError(
                "CUSTOM_OPENAI_BASE_URL environment variable is required"
            )  # æŠ›å‡ºé”™è¯¯ï¼šéœ€è¦åŸºç¡€URLç¯å¢ƒå˜é‡

        # è¿æ¥åˆ°Tavilyæœç´¢å®¢æˆ·ç«¯
        print("ğŸ”— æ­£åœ¨è¿æ¥åˆ°Tavilyæœç´¢å®¢æˆ·ç«¯...")
        await tavily_search_client.connect()  # è¿æ¥åˆ°Tavilyæœç´¢å®¢æˆ·ç«¯
        print("âœ… Tavilyæœç´¢å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")

        agent = DeepResearchAgent(  # åˆ›å»ºæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“å®ä¾‹
            name="Friday",  # è®¾ç½®æ™ºèƒ½ä½“åç§°
            sys_prompt="You are Friday, a helpful research assistant.",  # ç®€åŒ–ç³»ç»Ÿæç¤º
            model=OpenAIChatModel(  # é…ç½®OpenAIèŠå¤©æ¨¡å‹
                model_name=model_name,  # è®¾ç½®æ¨¡å‹åç§°
                api_key=api_key,  # è®¾ç½®APIå¯†é’¥
                client_args={"base_url": base_url},  # è®¾ç½®å®¢æˆ·ç«¯å‚æ•°
                stream=False,  # å…³é—­æµå¼è¾“å‡ºä»¥æé«˜ç¨³å®šæ€§
                generate_kwargs={  # æ·»åŠ ç”Ÿæˆå‚æ•°
                    "temperature": 0.7,  # è®¾ç½®æ¸©åº¦å‚æ•°
                    "max_tokens": 2048,  # å‡å°‘æœ€å¤§ä»¤ç‰Œæ•°ä»¥æé«˜å…¼å®¹æ€§
                },
            ),
            formatter=OpenAIChatFormatter(),  # è®¾ç½®èŠå¤©æ ¼å¼åŒ–å™¨
            memory=InMemoryMemory(),  # è®¾ç½®å†…å­˜å­˜å‚¨
            search_mcp_client=tavily_search_client,  # è®¾ç½®æœç´¢MCPå®¢æˆ·ç«¯
            tmp_file_storage_dir=agent_working_dir,  # è®¾ç½®ä¸´æ—¶æ–‡ä»¶å­˜å‚¨ç›®å½•
            max_iters=5,  # å‡å°‘æœ€å¤§è¿­ä»£æ¬¡æ•°ä»¥æé«˜ç¨³å®šæ€§
        )
        user_name = "Bob"  # è®¾ç½®ç”¨æˆ·å
        msg = Msg(  # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡
            user_name,  # è®¾ç½®å‘é€è€…
            content=user_query,  # è®¾ç½®æ¶ˆæ¯å†…å®¹
            role="user",  # è®¾ç½®è§’è‰²ä¸ºç”¨æˆ·
        )
        print("ğŸ¤– æ™ºèƒ½ä½“å·²åˆå§‹åŒ–ï¼Œå¼€å§‹å¤„ç†æŸ¥è¯¢...")
        result = await agent(msg)  # è°ƒç”¨æ™ºèƒ½ä½“å¤„ç†æ¶ˆæ¯
        print("âœ… æŸ¥è¯¢å¤„ç†å®Œæˆ")
        print("ğŸ“‹ ç ”ç©¶ç»“æœ:")
        print("=" * 60)
        print(result.get_text_content())
        print("=" * 60)
        logger.info(result)  # è®°å½•ç»“æœä¿¡æ¯

    except Exception as err:  # æ•è·å¼‚å¸¸
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {err}")
        import traceback
        traceback.print_exc()
        logger.exception(err)  # è®°å½•å¼‚å¸¸ä¿¡æ¯
    finally:
        try:
            print("ğŸ”Œ æ­£åœ¨å…³é—­Tavilyæœç´¢å®¢æˆ·ç«¯...")
            await tavily_search_client.close()  # å…³é—­Tavilyæœç´¢å®¢æˆ·ç«¯è¿æ¥
            print("âœ… Tavilyæœç´¢å®¢æˆ·ç«¯å·²å…³é—­")
        except Exception as e:
            print(f"âš ï¸ å…³é—­Tavilyæœç´¢å®¢æˆ·ç«¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            logger.warning(f"å…³é—­Tavilyæœç´¢å®¢æˆ·ç«¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":  # åˆ¤æ–­æ˜¯å¦ä¸ºä¸»ç¨‹åºå…¥å£
    query = (  # å®šä¹‰æŸ¥è¯¢é—®é¢˜
        "å¦‚æœåŸƒåˆ©ä¹Œå¾·Â·åŸºæ™®ä¹”æ ¼èƒ½å¤Ÿæ— é™æœŸåœ°ä¿æŒä»–åˆ›çºªå½•çš„"
        "é©¬æ‹‰æ¾é…é€Ÿï¼Œé‚£ä¹ˆä»–è·‘å®Œåœ°çƒåˆ°æœˆçƒæœ€è¿‘è·ç¦»"
        "éœ€è¦å¤šå°‘åƒå°æ—¶ï¼Ÿè¯·ä½¿ç”¨ç»´åŸºç™¾ç§‘æœˆçƒé¡µé¢ä¸Šçš„"
        "æœ€å°è¿‘åœ°ç‚¹å€¼æ¥è¿›è¡Œè®¡ç®—ã€‚å°†ç»“æœå››èˆäº”å…¥"
        "åˆ°æœ€æ¥è¿‘çš„1000å°æ—¶ï¼Œå¦‚æœ‰å¿…è¦è¯·ä¸è¦ä½¿ç”¨"
        "ä»»ä½•é€—å·åˆ†éš”ç¬¦ã€‚"
    )
    try:
        asyncio.run(main(query))  # è¿è¡Œä¸»å¼‚æ­¥å‡½æ•°
    except Exception as e:  # æ•è·å¼‚å¸¸
        print(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.exception(e)  # è®°å½•å¼‚å¸¸ä¿¡æ¯